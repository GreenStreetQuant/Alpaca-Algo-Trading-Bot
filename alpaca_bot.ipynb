{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alpaca_bot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMKBbPwMbwISbpZJJeYauk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreenStreetQuant/Alpaca-Algo-Trading-Bot/blob/master/alpaca_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJg3w5TJjALr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install yfinance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F7nsnxriz20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8a586551-ef66-421d-f474-757908df1254"
      },
      "source": [
        "import os\n",
        "import alpaca_trade_api as tradeapi\n",
        "import pandas as pd\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from feature_selector import FeatureSelector\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  from numpy.core.umath_tests import inner1d\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf8y1SDTk9rS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95ce0545-3cb7-4383-a7e2-a01a58bc3808"
      },
      "source": [
        "tsla = yf.download(\"TSLA\",period='2y')\n",
        "spy = yf.download(\"SPY\",period='2y')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_b-cD6Jl1Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exp_smooth_data(data):\n",
        "\n",
        "  smooth_list = []\n",
        "\n",
        "  #first value y for s \n",
        "  smooth_list.append(data.iloc[0])\n",
        "\n",
        "  for v in data[1:]:\n",
        "    st = 0.2 * v + (1 - 0.2) * smooth_list[-1]\n",
        "    smooth_list.append(st)\n",
        "\n",
        "  return smooth_list \n",
        "\n",
        "def computeRSI(data):\n",
        "    diff = data.diff(1).dropna()        # diff in one field(one day)\n",
        "\n",
        "    #this preservers dimensions off diff values\n",
        "    up_chg = 0 * diff\n",
        "    down_chg = 0 * diff\n",
        "    \n",
        "    # up change is equal to the positive difference, otherwise equal to zero\n",
        "    up_chg[diff > 0] = diff[ diff > 0]\n",
        "    \n",
        "    # down change is equal to negative deifference, otherwise equal to zero\n",
        "    down_chg[diff < 0] = diff[ diff < 0 ]\n",
        "    \n",
        "    # check pandas documentation for ewm\n",
        "    # we set com=time_window-1 so we get decay alpha=1/time_window\n",
        "\n",
        "    up_chg_avg   = up_chg.ewm(com=14-1 , min_periods=14).mean()\n",
        "    down_chg_avg = down_chg.ewm(com=14-1 , min_periods=14).mean()\n",
        "    \n",
        "    \n",
        "    rs = abs(up_chg_avg/down_chg_avg)\n",
        "    rsi = 100 - 100/(1+rs)\n",
        "    return rsi\n",
        "\n",
        "def get_features(tsla,spy):\n",
        "\n",
        "  df_smoothed = pd.DataFrame()\n",
        "\n",
        "  close_smooth = exp_smooth_data(tsla['Close'])\n",
        "\n",
        "  df_smoothed['close_smooth'] = close_smooth\n",
        "\n",
        "  open_smooth = exp_smooth_data(tsla['Open'])\n",
        "\n",
        "  df_smoothed['Open_smooth'] = open_smooth\n",
        "\n",
        "  high_smooth = exp_smooth_data(tsla['High'])\n",
        "\n",
        "  df_smoothed['high_smooth'] = high_smooth\n",
        "\n",
        "  low_smooth = exp_smooth_data(tsla['Low'])\n",
        "\n",
        "  df_smoothed['low_smooth'] = low_smooth\n",
        "\n",
        "  volume_smooth = exp_smooth_data(tsla['Volume'])\n",
        "\n",
        "  df_smoothed['volume_smooth'] = volume_smooth\n",
        "\n",
        "  df_sp_smoothed = pd.DataFrame()\n",
        "\n",
        "  close_smooth_sp = exp_smooth_data(spy['Close'])\n",
        "\n",
        "  df_sp_smoothed['close_smooth'] = close_smooth_sp\n",
        "\n",
        "  df_smoothed['rsi'] = computeRSI(df_smoothed['close_smooth'])\n",
        "  df_smoothed['william'] = (df_smoothed['high_smooth'].rolling(14).max() - df_smoothed['close_smooth'])/(df_smoothed['high_smooth'].rolling(14).max() - df_smoothed['low_smooth'].rolling(14).min()) * -100\n",
        "  df_smoothed['stch_osc'] = 100 * (df_smoothed['close_smooth'] - df_smoothed['low_smooth'].rolling(14).min())/(df_smoothed['high_smooth'].rolling(14).max() - df_smoothed['low_smooth'].rolling(14).min())\n",
        "  df_smoothed['price_rate_change'] = (df_smoothed['close_smooth'] - df_smoothed['close_smooth'].shift(14))/df_smoothed['close_smooth'].shift(14)\n",
        "  df_smoothed['log_price'] = np.log(df_smoothed['close_smooth'])\n",
        "  df_smoothed['log_mov'] = df_smoothed['log_price'].rolling(6).mean()\n",
        "  df_smoothed['log_diff'] = df_smoothed['log_price'] - df_smoothed['log_mov']\n",
        "  df_smoothed['fast_mov'] = df_smoothed['close_smooth'].rolling(3).mean()\n",
        "  df_smoothed['slow_mov'] = df_smoothed['close_smooth'].rolling(7).mean()\n",
        "  df_smoothed['mov_diff'] = df_smoothed['fast_mov'] - df_smoothed['slow_mov']\n",
        "  df_smoothed['mac_fast'] = df_smoothed['close_smooth'].rolling(7).mean()\n",
        "  df_smoothed['mac_slow'] = df_smoothed['close_smooth'].rolling(20).mean()\n",
        "  df_smoothed['mac_diff'] = df_smoothed['mac_fast'] - df_smoothed['mac_slow']\n",
        "  df_smoothed['volume_log'] = np.log(df_smoothed['volume_smooth'])\n",
        "  df_smoothed['pct_change'] = df_smoothed['close_smooth'].pct_change()\n",
        "  df_smoothed['z_score'] = (df_smoothed['close_smooth'] - df_smoothed['close_smooth'].rolling(7).mean())/df_smoothed['close_smooth'].std()\n",
        "  df_smoothed['sp_return'] = df_sp_smoothed['close_smooth'].pct_change(14)\n",
        "  df_smoothed['return_two_week'] = df_smoothed['close_smooth'].pct_change(14)\n",
        "  df_smoothed['return_day'] = df_smoothed['close_smooth'].pct_change(1)\n",
        "  df_smoothed['return_month'] = df_smoothed['close_smooth'].pct_change(5)\n",
        "  df_smoothed['return_two_day'] = df_smoothed['close_smooth'].pct_change(2)\n",
        "  df_smoothed['return_week'] = df_smoothed['close_smooth'].pct_change(5)\n",
        "  df_smoothed['return_diff_sp'] = df_smoothed['return_day'] - df_smoothed['sp_return']\n",
        "  df_smoothed['return_sp_std'] = df_smoothed['sp_return'].rolling(14).std()\n",
        "  df_smoothed['return_std'] = df_smoothed['return_week'].rolling(14).std()\n",
        "  df_smoothed['last_close'] = df_smoothed['close_smooth'].shift(14)\n",
        "  df_smoothed['last_open'] = df_smoothed['Open_smooth'].shift(14)\n",
        "  df_smoothed['last_high'] = df_smoothed['high_smooth'].shift(14)\n",
        "  df_smoothed['last_low'] = df_smoothed['low_smooth'].shift(14)\n",
        "  df_smoothed['high_low'] = df_smoothed['last_high'] - df_smoothed['last_low']\n",
        "  df_smoothed.head()\n",
        "\n",
        "  df_smoothed = df_smoothed.dropna()\n",
        "\n",
        "  df_complete = df_smoothed\n",
        "\n",
        "  df_complete['win'] = np.where((df_complete['close_smooth'].shift(-5) > df_complete['close_smooth']), 1, 0)\n",
        "  return df_complete\n",
        "\n",
        "def get_bearish_or_bullish_signal(df_complete):\n",
        "  train = df_complete.drop(columns=['win'])\n",
        "  train_labels = df_complete['win']\n",
        "  fs = FeatureSelector(data=train, labels=train_labels)\n",
        "  fs.identify_collinear(correlation_threshold=0.975)\n",
        "  fs.identify_zero_importance(task='regression',eval_metric='auc',n_iterations=10,early_stopping=True)\n",
        "  fs.identify_low_importance(cumulative_importance = 0.99)\n",
        "  all_to_remove = fs.check_removal()\n",
        "  clean_removed_db = train.drop(columns = all_to_remove)\n",
        "  split = len(clean_removed_db)-1\n",
        "  X_train, X_test = clean_removed_db, clean_removed_db[split:]\n",
        "  y_train = train_labels\n",
        "  classifier = RandomForestClassifier(n_estimators=3,max_depth=30,max_features='sqrt',min_samples_leaf=27,min_samples_split=2,random_state=42)\n",
        "  classifier.fit(X_train,y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  return y_pred\n",
        "\n",
        "  \n",
        "def buy_or_sell_signal():\n",
        "  data = get_features(tsla,spy)\n",
        "  signal = get_bearish_or_bullish_signal(data)\n",
        "\n",
        "  prediction = signal.tolist()\n",
        "  return prediction"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyOb9OVujFh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rf_trading_algo():\n",
        "    \n",
        "    \n",
        "    os.environ[\"APCA_API_BASE_URL\"] = \"https://paper-api.alpaca.markets\"\n",
        "\n",
        "    api = tradeapi.REST('asdf','asdf',api_version='v2') # or use ENV Vars shown below\n",
        "    account = api.get_account()\n",
        "\n",
        "    sender_address = 'greenstreetquantitative@gmail.com'\n",
        "    sender_pass = 'asdf!'\n",
        "    receiver_address = 'sentive.landry@gmail.com'\n",
        "\n",
        "    message = MIMEMultipart()\n",
        "    message['From'] = 'Algo Bot'\n",
        "    message['To'] = receiver_address\n",
        "    message['Subject'] = 'Random Forest Algo'\n",
        "\n",
        "    portfolio = api.list_positions()\n",
        "    clock = api.get_clock()\n",
        "    cash = float(account.buying_power)\n",
        "\n",
        "    symbols = \"TSLA\"\n",
        "    \n",
        "    number_of_shares = cash * 0.50\n",
        "\n",
        "    signal = buy_or_sell_signal()\n",
        "\n",
        "    if clock.is_open == True:\n",
        "      if bool(portfolio) == False:\n",
        "        if signal == 1:\n",
        "          api.submit_order(symbol=symbols, qty=number_of_shares,side='buy',type='market',time_in_force='day')\n",
        "          mail_content = \"Bought shares of TSLA\"\n",
        "      else:\n",
        "        if signal == 0:\n",
        "          api.close_position(symbols)\n",
        "          mail_content = \"Closed positions of TSLA\"\n",
        "    else:\n",
        "      mail_content = \"The Market Is Closed\"\n",
        "\n",
        "    message.attach(MIMEText(mail_content, 'plain'))\n",
        "\n",
        "    session = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "    session.starttls() \n",
        "    session.login(sender_address, sender_pass) \n",
        "    text = message.as_string()\n",
        "    session.sendmail(sender_address, receiver_address, text)\n",
        "    session.quit()\n",
        "    \n",
        "    done = 'Mail Sent'\n",
        "    return done"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXlpAtopkSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "outputId": "02026e5b-2703-4b93-c7a8-4bf8b70ea7c4"
      },
      "source": [
        "rf_trading_algo()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17 features with a correlation magnitude greater than 0.97.\n",
            "\n",
            "Training Gradient Boosting Model\n",
            "\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[233]\tvalid_0's auc: 0.969156\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[478]\tvalid_0's auc: 0.973684\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[539]\tvalid_0's auc: 0.977273\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[330]\tvalid_0's auc: 0.979708\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[186]\tvalid_0's auc: 0.977778\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[316]\tvalid_0's auc: 0.972493\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[350]\tvalid_0's auc: 0.994387\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[386]\tvalid_0's auc: 0.972735\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[381]\tvalid_0's auc: 0.947649\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "Early stopping, best iteration is:\n",
            "[355]\tvalid_0's auc: 0.972222\n",
            "\n",
            "7 features with zero importance after one-hot encoding.\n",
            "\n",
            "25 features required for cumulative importance of 0.99 after one hot encoding.\n",
            "10 features do not contribute to cumulative importance of 0.99.\n",
            "\n",
            "Total of 19 features identified for removal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Mail Sent'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}